{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Tools\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "F:\\Tools\\Anaconda3\\lib\\site-packages\\sklearn\\grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nconn = pymysql.connect(host=\\'192.168.1.131\\',user=\\'yichen\\', password=\\'0000\\', database=\\'yelp_db\\', charset=\\'utf8\\')\\ncur = conn.cursor()\\n\\n#query=\"select id as user_id, review_count,yelping_since,useful,funny,cool,fans,average_stars, compliment_hot+ compliment_more+ compliment_profile+ compliment_cute+ compliment_list+ compliment_note+ compliment_plain+compliment_cool+compliment_funny+compliment_writer+compliment_photos as sum_compliment from user\"\\nquery=\\'select id as review_id,business_id,user_id,stars,date,useful,funny,cool from review\\'\\ncur.execute(query)\\n#cur.execute(\\'commit\\')\\nt=cur.fetchall()\\n#user_info_50000=pd.DataFrame(list(t), columns = [i[0] for i in cur.description])\\nreview_info_notext=pd.DataFrame(list(t), columns = [i[0] for i in cur.description])\\nprint(\\'done\\')\\nreview_info_notext.to_csv(\\'E:/DATA/DATA in CU Boulder/CSCI 5622/review_info_notext.csv\\')\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import pymysql\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.model_selection import train_test_split#,GridSearchCV\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.svm import SVC  \n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn import cross_validation,metrics\n",
    "from sklearn import linear_model\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix, roc_auc_score, classification_report, roc_curve, auc  \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.pipeline import FeatureUnion, Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "'''\n",
    "conn = pymysql.connect(host='192.168.1.131',user='yichen', password='0000', database='yelp_db', charset='utf8')\n",
    "cur = conn.cursor()\n",
    "\n",
    "#query=\"select id as user_id, review_count,yelping_since,useful,funny,cool,fans,average_stars, compliment_hot+ compliment_more+ compliment_profile+ compliment_cute+ compliment_list+ compliment_note+ compliment_plain+compliment_cool+compliment_funny+compliment_writer+compliment_photos as sum_compliment from user\"\n",
    "query='select id as review_id,business_id,user_id,stars,date,useful,funny,cool from review'\n",
    "cur.execute(query)\n",
    "#cur.execute('commit')\n",
    "t=cur.fetchall()\n",
    "#user_info_50000=pd.DataFrame(list(t), columns = [i[0] for i in cur.description])\n",
    "review_info_notext=pd.DataFrame(list(t), columns = [i[0] for i in cur.description])\n",
    "print('done')\n",
    "review_info_notext.to_csv('E:/DATA/DATA in CU Boulder/CSCI 5622/review_info_notext.csv')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Tools\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2698: DtypeWarning: Columns (25,26) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "all_withoutTextFea=pd.read_csv('review_cat_user_userFeature.csv')\n",
    "del all_withoutTextFea['Unnamed: 0']\n",
    "text1=pd.read_csv('review_data.csv')\n",
    "text2=pd.read_csv('data_final.csv')\n",
    "user_userFea_business_50000=pd.read_csv('user_userFea_business_50000.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_ori=text1[['review_id','reviews']]\n",
    "text_polar_sub=text2[['review_id','reviews_polarity','reviews_subjectivity']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#del user_userFea_business_50000['Unnamed: 0']\n",
    "#unique_id=text2[['review_id']].drop_duplicates()\n",
    "#text_polar_sub_unique=pd.merge(text_ori,text_polar_sub,how='inner',on='review_id')\n",
    "#all_without_len_uc=pd.merge(text_polar_sub_unique,user_userFea_business_50000,how='inner',on='review_id')\n",
    "#text_ori['review_length']=0\n",
    "#for i in range(len(text_ori)):\n",
    "#    text_ori['review_length'][i]=len(text_ori['reviews'][i].split())\n",
    "#all_features=pd.merge(all_withoutTextFea,all_without_len_uc[['review_id','reviews','reviews_polarity','reviews_subjectivity']],on='review_id',how='inner')\n",
    "#all_features.to_csv('all_features_without_tfidfBoG.csv')\n",
    "#all_features_without_uc\n",
    "\n",
    "\n",
    "\n",
    "#all_features_without_uc=pd.read_csv('all_features_without_uc_tfidfBoG.csv',encoding='gb18030')\n",
    "#all_features\n",
    "#del all_features['Unnamed: 0']\n",
    "#del all_features_without_uc['Unnamed: 0']\n",
    "\n",
    "#all_features_notfidfBoG\n",
    "#business=all_features_without_uc[['business_id','business_stars']].drop_duplicates()\n",
    "#all_features_notfidfBoG=pd.merge(all_features,business,how='inner',on='business_id')\n",
    "all_features_notfidfBoG=pd.read_csv('all_features_noTFIDFBoG.csv',encoding='gb18030')\n",
    "#all_without_uctfidfBoG=pd.read_csv('all_features_noUC_TFIDFBoG.csv',encoding='gb18030')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OtherFeatureTransformer(BaseEstimator, TransformerMixin):  \n",
    "    def __init__(self):\n",
    "        self.feature_names=[]\n",
    "    def fit(self, examples):\n",
    "        # return self and nothing else \n",
    "        return self\n",
    "\n",
    "    def transform(self, examples):\n",
    "        #print(len(examples))\n",
    "        from scipy.sparse import csr_matrix\n",
    "        self.X = np.zeros((len(examples[0]), 20))\n",
    "        \n",
    "        for j in range(20):\n",
    "            #for i in range(len(examples[0])):\n",
    "            self.X[:,j] = examples[j]\n",
    "        #print(self.X.shape)\n",
    "        return csr_matrix(self.X)\n",
    "    def get_feature_names(self):\n",
    "        return self.feature_names \n",
    "class Feat:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def build_train_features(self, examples):\n",
    "        self.tfidf= TfidfVectorizer(stop_words = 'english',analyzer='word',ngram_range=(1,4))\n",
    "        self.count=CountVectorizer()\n",
    "        self.other=OtherFeatureTransformer()\n",
    "        self.vectorizer = FeatureUnion( \n",
    "        [       \n",
    "             #word tfidf\n",
    "            ('tfidf', \n",
    "              Pipeline([('extract_field', FunctionTransformer(lambda x: x[0], validate = False)),\n",
    "                        ('count',self.tfidf)])),            \n",
    "             #appearance of some tropes\n",
    "            ('bagofwords', \n",
    "              Pipeline([('extract_field', FunctionTransformer(lambda x: x[0], validate = False)),\n",
    "                        ('count', self.count)])),\n",
    "             #type of sentiment\n",
    "            ('other features', \n",
    "            Pipeline([('extract_field', FunctionTransformer(lambda x: [x[1],x[2],x[3],x[4],x[5],x[6],x[7],x[8],x[9],x[10],x[11],\n",
    "                                                                       x[12],x[13],x[14],x[15],x[16],x[17],x[18],x[19],x[20],],\n",
    "                                                            validate = False)),\n",
    "                        ('other', self.other)]))\n",
    "            #\n",
    "            #('other features', \n",
    "            # Pipeline([('extract_field', FunctionTransformer(lambda x: [x[1],x[2],x[3],x[4],x[5],x[6],x[7],x[8],x[9],x[10],x[11],x[12],x[13],x[14]], validate = False)),\n",
    "            #            ('other', self.other)]))\n",
    "    \n",
    "        ])\n",
    "        return self.vectorizer.fit_transform(examples)\n",
    "    def build_test_features(self,examples):\n",
    "        return self.vectorizer.transform(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training labels generated\n",
      "testing labels generated\n"
     ]
    }
   ],
   "source": [
    "train, test = train_test_split(all_features_notfidfBoG, test_size=0.2)\n",
    "train_fea=train\n",
    "test_fea=test\n",
    "train_lab=[]\n",
    "test_lab=[]\n",
    "ini=0\n",
    "for index, row in train.iterrows():\n",
    "    if row['review_stars'] ==5:\n",
    "        train_lab.append(5)\n",
    "    elif (row['review_stars'] ==4):\n",
    "        train_lab.append(4)\n",
    "    elif row['review_stars'] == 3:\n",
    "        train_lab.append(3)\n",
    "    elif row['review_stars'] ==2:\n",
    "        train_lab.append(2)\n",
    "    else:\n",
    "        train_lab.append(1)\n",
    "    ini += 1\n",
    "print('training labels generated')\n",
    "ini = 0\n",
    "for index, row in test.iterrows():\n",
    "    if row['review_stars'] ==5:\n",
    "        test_lab.append(5)\n",
    "    elif (row['review_stars'] ==4):\n",
    "        test_lab.append(4)\n",
    "    elif row['review_stars'] == 3:\n",
    "        test_lab.append(3)\n",
    "    elif row['review_stars'] ==2:\n",
    "        test_lab.append(2)\n",
    "    else:\n",
    "        test_lab.append(1)\n",
    "    ini += 1 \n",
    "print('testing labels generated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "getFeat=Feat()\n",
    "#train_feature=getFeat.build_train_features([list(train_fea['user_review_count']),list(train_fea['user_useful']),list(train_fea['user_funny']),list(train_fea['user_cool']),list(train_fea['user_fans']),list(train_fea['user_average_stars']),list(train_fea['user_sum_compliment'])])\n",
    "#test_feature=getFeat.build_test_features([list(test_fea['user_review_count']),list(test_fea['user_useful']),list(test_fea['user_funny']),list(test_fea['user_cool']),list(test_fea['user_fans']),list(test_fea['user_average_stars']),list(test_fea['user_sum_compliment'])])\n",
    "train_feature=getFeat.build_train_features([list(train_fea['reviews']),list(train_fea['reviews_polarity']),\n",
    "                                            list(train_fea['reviews_subjectivity']),list(train_fea['business_stars']),\n",
    "                                            list(train_fea['review_stars']),list(train_fea['review_useful']),list(train_fea['review_funny']),\n",
    "                                            list(train_fea['review_cool']),list(train_fea['user_review_count']),\n",
    "                                            list(train_fea['user_useful']),list(train_fea['user_funny']),list(train_fea['user_cool']),\n",
    "                                            list(train_fea['user_fans']),list(train_fea['user_average_stars']),\n",
    "                                            list(train_fea['user_sum_compliment']),list(train_fea['uc_review_count']),\n",
    "                                            list(train_fea['uc_avg_stars']),list(train_fea['uc_avg_review_useful']),\n",
    "                                            list(train_fea['uc_avg_review_funny']),list(train_fea['uc_avg_review_cool']),\n",
    "                                            list(train_fea['business_stars'])\n",
    "])\n",
    "test_feature=getFeat.build_test_features([list(test_fea['reviews']),list(test_fea['reviews_polarity']),\n",
    "                                          list(test_fea['reviews_subjectivity']),list(test_fea['business_stars']),\n",
    "                                          list(test_fea['review_stars']),list(test_fea['review_useful']),list(test_fea['review_funny']),\n",
    "                                          list(test_fea['review_cool']),list(test_fea['user_review_count']),\n",
    "                                          list(test_fea['user_useful']),list(test_fea['user_funny']),list(test_fea['user_cool']),\n",
    "                                          list(test_fea['user_fans']),list(test_fea['user_average_stars']),\n",
    "                                          list(test_fea['user_sum_compliment']),list(test_fea['uc_review_count']),\n",
    "                                          list(test_fea['uc_avg_stars']),list(test_fea['uc_avg_review_useful']),\n",
    "                                          list(test_fea['uc_avg_review_funny']),list(test_fea['uc_avg_review_cool']),\n",
    "                                          list(test_fea['business_stars'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_features_notfidfBoG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### scale the data first\n",
    "#scaler = preprocessing.StandardScaler().fit(train_feature)\n",
    "#scaler.transform(train_feature)\n",
    "#scaler.transform(test_feature)\n",
    "train_feature=Normalizer().fit_transform(train_feature)\n",
    "test_feature=Normalizer().fit_transform(test_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACC: 0.7744354063993907\n",
      "[[21743    51    42   932   215]\n",
      " [  894  6110  1829  5597   323]\n",
      " [    8   841  5324 13971   829]\n",
      " [    3    99   710 31159  9078]\n",
      " [    2     3    39  4216 71905]]\n",
      "RMSE: 0.6435823623997685\n"
     ]
    }
   ],
   "source": [
    "#logreg = linear_model.LogisticRegression(C=10.0)\n",
    "#logreg.fit(train_feature, train_lab)\n",
    "\n",
    "#pred_logreg = logreg.predict(test_feature)\n",
    "#acc_logreg = logreg.score(test_rev_lst,test_lab_lst)\n",
    "#pred_proba_logreg=logreg.predict_proba(test_feature)\n",
    "print('ACC:',precision_score(test_lab,pred_logreg,average='micro'))  \n",
    "\n",
    "#print('AUC:',metrics.roc_auc_score(test_lab,pred_proba_logreg[:,1]))#验证集上的auc值\n",
    "#print('F1:',metrics.f1_score(test_lab,pred_logreg))\n",
    "#print('Recall:',metrics.recall_score(test_lab,pred_logreg))\n",
    "#print('the auc of logistic regression is %f' %test_auc)\n",
    "print(metrics.confusion_matrix(test_lab,pred_logreg))#验证集上的混淆矩阵\n",
    "print('RMSE:',math.sqrt(metrics.mean_squared_error(test_lab,pred_logreg)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<703688x22447295 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 197963052 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
